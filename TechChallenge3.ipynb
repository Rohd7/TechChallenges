{"cells":[{"cell_type":"markdown","metadata":{"id":"cI716UHsEfHs"},"source":["‚úÖ Parte 1: Prepara√ß√£o do Ambiente e dos Dados\n","O que est√° acontecendo:\n","Instalamos as depend√™ncias.\n","\n","Carregamos o dataset JSON.\n","\n","Preparamos os dados no formato de instru√ß√£o-resposta (Instruction Tuning), onde:\n","\n","Instru√ß√£o: \"Pergunta sobre t√≠tulo X: Y?\"\n","\n","Resposta: \"Descri√ß√£o do produto.\"\n","\n"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18306,"status":"ok","timestamp":1748294285744,"user":{"displayName":"Rodrigo Lopes","userId":"06191758959451429758"},"user_tz":180},"id":"tMj53nhrER2T","outputId":"a2096464-7c5d-46ac-bbaa-a01f5d387624"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":103311,"status":"ok","timestamp":1748294389058,"user":{"displayName":"Rodrigo Lopes","userId":"06191758959451429758"},"user_tz":180},"id":"Oh8nJUkwGfei","outputId":"84e650a9-b562-4423-9eae-4bce199d049c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["# Instalar depend√™ncias\n","!pip install -q transformers datasets peft bitsandbytes accelerate"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1107,"status":"ok","timestamp":1748294390168,"user":{"displayName":"Rodrigo Lopes","userId":"06191758959451429758"},"user_tz":180},"id":"5-SHDD3AGiAa","outputId":"dc31acea-46d9-4ad1-89f3-4f5c6a8e1445"},"outputs":[{"output_type":"stream","name":"stdout","text":["[{'uid': '0000031909', 'title': 'Girls Ballet Tutu Neon Pink', 'content': 'High quality 3 layer ballet tutu. 12 inches in length', 'target_ind': [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 111], 'target_rel': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, {'uid': '0000032034', 'title': 'Adult Ballet Tutu Yellow', 'content': '', 'target_ind': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 16, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71], 'target_rel': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, {'uid': '0000913154', 'title': 'The Way Things Work: An Illustrated Encyclopedia of Technology', 'content': '', 'target_ind': [116, 117, 118, 119, 120, 121, 122], 'target_rel': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, {'uid': '0001360000', 'title': \"Mog's Kittens\", 'content': 'Judith Kerr&#8217;s best&#8211;selling adventures of that endearing (and exasperating) cat Mog have entertained children for more than 30 years. Now, even infants and toddlers can enjoy meeting this loveable feline. These sturdy little board books&#8212;with their bright, simple pictures, easy text, and hand&#8211;friendly formats&#8212;are just the thing to delight the very young. Ages 6 months&#8211;2 years.', 'target_ind': [146, 147, 148, 149, 495], 'target_rel': [1.0, 1.0, 1.0, 1.0, 1.0]}, {'uid': '0001381245', 'title': 'Misty of Chincoteague', 'content': '', 'target_ind': [151], 'target_rel': [1.0]}, {'uid': '0001371045', 'title': \"Hilda Boswell's treasury of children's stories: A new anthology of stories for the young\", 'content': '', 'target_ind': [150], 'target_rel': [1.0]}, {'uid': '0000230022', 'title': 'The Simple Truths of Service: Inspired by Johnny the Bagger', 'content': '', 'target_ind': [184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201], 'target_rel': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, {'uid': '0000031895', 'title': 'Girls Ballet Tutu Neon Blue', 'content': 'Dance tutu for girls ages 2-8 years. Perfect for dance practice, recitals and performances, costumes or just for fun!', 'target_ind': [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 31, 33, 42, 46, 54, 58, 111, 113, 125, 126, 159, 163, 202, 203, 204, 205, 206, 207], 'target_rel': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, {'uid': '0000174076', 'title': 'Evaluating Research in Academic Journals - A Practical Guide to Realistic Evaluation (5th Fifth Edition) - By Fred Pyrczak', 'content': '', 'target_ind': [106, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249], 'target_rel': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, {'uid': '0001713086', 'title': 'Dr. Seuss ABC (Dr.Seuss Classic Collection) (Spanish Edition)', 'content': '', 'target_ind': [260, 261, 262, 263, 264, 265, 266, 267], 'target_rel': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}]\n"]}],"source":["import json\n","\n","data = []\n","with open('/content/drive/MyDrive/Colab Notebooks/Datasets/trn.json') as f:\n","    for i, line in enumerate(f):\n","        data.append(json.loads(line))\n","        if i >= 9:  # pega s√≥ os 10 primeiros para inspe√ß√£o\n","            break\n","\n","print(data)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2175,"status":"ok","timestamp":1748294392359,"user":{"displayName":"Rodrigo Lopes","userId":"06191758959451429758"},"user_tz":180},"id":"Qium6ZvPE9rT","outputId":"8e2f6e79-892f-4747-ecef-e429c74bb8f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["[{'uid': '0000031909', 'title': 'Girls Ballet Tutu Neon Pink', 'content': 'High quality 3 layer ballet tutu. 12 inches in length', 'target_ind': [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 111], 'target_rel': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, {'uid': '0000032034', 'title': 'Adult Ballet Tutu Yellow', 'content': '', 'target_ind': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 16, 33, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71], 'target_rel': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, {'uid': '0000913154', 'title': 'The Way Things Work: An Illustrated Encyclopedia of Technology', 'content': '', 'target_ind': [116, 117, 118, 119, 120, 121, 122], 'target_rel': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, {'uid': '0001360000', 'title': \"Mog's Kittens\", 'content': 'Judith Kerr&#8217;s best&#8211;selling adventures of that endearing (and exasperating) cat Mog have entertained children for more than 30 years. Now, even infants and toddlers can enjoy meeting this loveable feline. These sturdy little board books&#8212;with their bright, simple pictures, easy text, and hand&#8211;friendly formats&#8212;are just the thing to delight the very young. Ages 6 months&#8211;2 years.', 'target_ind': [146, 147, 148, 149, 495], 'target_rel': [1.0, 1.0, 1.0, 1.0, 1.0]}, {'uid': '0001381245', 'title': 'Misty of Chincoteague', 'content': '', 'target_ind': [151], 'target_rel': [1.0]}, {'uid': '0001371045', 'title': \"Hilda Boswell's treasury of children's stories: A new anthology of stories for the young\", 'content': '', 'target_ind': [150], 'target_rel': [1.0]}, {'uid': '0000230022', 'title': 'The Simple Truths of Service: Inspired by Johnny the Bagger', 'content': '', 'target_ind': [184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201], 'target_rel': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, {'uid': '0000031895', 'title': 'Girls Ballet Tutu Neon Blue', 'content': 'Dance tutu for girls ages 2-8 years. Perfect for dance practice, recitals and performances, costumes or just for fun!', 'target_ind': [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 31, 33, 42, 46, 54, 58, 111, 113, 125, 126, 159, 163, 202, 203, 204, 205, 206, 207], 'target_rel': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, {'uid': '0000174076', 'title': 'Evaluating Research in Academic Journals - A Practical Guide to Realistic Evaluation (5th Fifth Edition) - By Fred Pyrczak', 'content': '', 'target_ind': [106, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249], 'target_rel': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}, {'uid': '0001713086', 'title': 'Dr. Seuss ABC (Dr.Seuss Classic Collection) (Spanish Edition)', 'content': '', 'target_ind': [260, 261, 262, 263, 264, 265, 266, 267], 'target_rel': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]}]\n","          uid                                              title  \\\n","0  0000031909                        Girls Ballet Tutu Neon Pink   \n","1  0000032034                           Adult Ballet Tutu Yellow   \n","2  0000913154  The Way Things Work: An Illustrated Encycloped...   \n","3  0001360000                                      Mog's Kittens   \n","4  0001381245                              Misty of Chincoteague   \n","\n","                                             content  \\\n","0  High quality 3 layer ballet tutu. 12 inches in...   \n","1                                                      \n","2                                                      \n","3  Judith Kerr&#8217;s best&#8211;selling adventu...   \n","4                                                      \n","\n","                                          target_ind  \\\n","0  [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 2...   \n","1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 16, 33, 36, 37,...   \n","2                [116, 117, 118, 119, 120, 121, 122]   \n","3                          [146, 147, 148, 149, 495]   \n","4                                              [151]   \n","\n","                                          target_rel  \n","0  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n","1  [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, ...  \n","2                [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]  \n","3                          [1.0, 1.0, 1.0, 1.0, 1.0]  \n","4                                              [1.0]  \n","{'instruction': \"Pergunta sobre o t√≠tulo 'Girls Ballet Tutu Neon Pink': Descreva o produto.\", 'response': 'High quality 3 layer ballet tutu. 12 inches in length'}\n"]}],"source":["\n","\n","# Importar bibliotecas\n","import json\n","import pandas as pd\n","from datasets import Dataset\n","\n","data = []\n","with open('/content/drive/MyDrive/Colab Notebooks/Datasets/trn.json') as f:\n","    for i, line in enumerate(f):\n","        data.append(json.loads(line))\n","        if i >= 9:  # pega s√≥ os 10 primeiros para inspe√ß√£o\n","            break\n","\n","print(data)\n","\n","# Converter em DataFrame\n","df = pd.DataFrame(data)\n","\n","# Visualizar primeiras linhas\n","print(df.head())\n","\n","# Preparar dados no formato de instru√ß√£o\n","def prepare_instruction(row):\n","    return {\n","        'instruction': f\"Pergunta sobre o t√≠tulo '{row['title']}': Descreva o produto.\",\n","        'response': row['content']\n","    }\n","\n","prepared_data = df.apply(prepare_instruction, axis=1).tolist()\n","\n","# Converter para Hugging Face Dataset\n","dataset = Dataset.from_list(prepared_data)\n","\n","# Ver exemplo\n","print(dataset[0])\n"]},{"cell_type":"markdown","metadata":{"id":"fNLc_IjbIrB4"},"source":["‚úÖ Parte 2: Carregamento do Modelo Base e Avalia√ß√£o Antes do Fine-Tuning\n","O que est√° acontecendo:\n","Carregamos um modelo base TinyLlama/TinyLlama-1.1B-Chat-v1.0.\n","\n","Testamos como o modelo responde antes do fine-tuning.\n","\n","Isso cria um baseline de compara√ß√£o."]},{"cell_type":"markdown","metadata":{"id":"nafuzBIuJWpX"},"source":["1Ô∏è‚É£ Instalar bibliotecas necess√°rias"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26611,"status":"ok","timestamp":1748294418967,"user":{"displayName":"Rodrigo Lopes","userId":"06191758959451429758"},"user_tz":180},"id":"_rLMtvEfJTHw","outputId":"96d0e0e3-085d-409a-910a-be3be584f426"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n","Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.45.5)\n","Requirement already satisfied: torch<3,>=2.0 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.6.0+cu124)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3,>=2.0->bitsandbytes) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3,>=2.0->bitsandbytes) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3,>=2.0->bitsandbytes) (3.0.2)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n","Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n","Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.31.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.4.26)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n"]}],"source":["!pip install transformers\n","!pip install bitsandbytes\n","!pip install accelerate\n","!pip install sentencepiece\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51262,"status":"ok","timestamp":1748295371826,"user":{"displayName":"Rodrigo Lopes","userId":"06191758959451429758"},"user_tz":180},"id":"VEIf3WuSLrP1","outputId":"b0f296f6-59de-419b-c08b-85d24af62574"},"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cpu\n","Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"output_type":"stream","name":"stdout","text":["Generated Answer By TinyLlama Without Fine-Tuning Training:\n"," Girls Ballet Tutu Neon is a lightweight, breathable, and stretchy tutu that is perfect for children's ballet performances and other dance events. It features bright neon colors and is designed to complement a child's outfit. The tutu is made of a blend of polyester and spandex, which makes it comfortable, flexible, and durable. The ne\n"]}],"source":["from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n","\n","model_checkpoint = \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n","base_model = AutoModelForCausalLM.from_pretrained(model_checkpoint)\n","\n","generator = pipeline(\"text-generation\", model=base_model, tokenizer=tokenizer)\n","\n","prompt = \"Question: What is Girls Ballet Tutu Neon?\\nAnswer:\"\n","\n","result = generator(prompt, max_length=100, do_sample=True, temperature=0.7)\n","generated_text = result[0]['generated_text']\n","generated_only = generated_text[len(prompt):]\n","\n","print(\"Generated Answer By TinyLlama Without Fine-Tuning Training:\")\n","print(generated_only)\n"]},{"cell_type":"markdown","metadata":{"id":"QWdzFrRqNAoU"},"source":["‚úÖ Parte 3: Fine-tuning com PEFT (LoRA)\n","O que est√° acontecendo:\n","Realizamos fine-tuning eficiente com LoRA, que evita treinar todos os par√¢metros do modelo.\n","\n","Criamos um Trainer e fazemos o ajuste.\n","\n","Usamos poucos epochs, pois a ideia √© apenas ilustrar."]},{"cell_type":"markdown","metadata":{"id":"ElDHVUAgOUib"},"source":["ETAPAS ‚úà:\n","\n","* Configura o LoRA\tDefine como o modelo vai ser adaptado (leve e eficiente)\n","\n","* Aplica LoRA no modelo\tInsere as camadas LoRA no modelo base\n","\n","* Tokeniza os dados\tTransforma dados (instruction + response) em tokens para o modelo\n","\n","* Prepara batches\tUsa o DataCollator para preparar os batches com padding e labels\n","\n","* Define argumentos de treino\tComo batch size, epochs, onde salvar etc.\n","\n","* Cria Trainer\tJunta tudo e gerencia o ciclo de treinamento\n","Executa treinamento\tAjusta os par√¢metros LoRA com base nos dados\n"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":280,"referenced_widgets":["547c50db9da34732bc3de6be1a19e1af","d6cd2f1ec6bd4fc4a39da8a7206770e4","0912fdd889f34d2691c29e9a2b16fb36","c27ffa6bc4b04a3085bfadafc19237af","34f5eebd41ca438ea93a7d609e55b1e8","d3280a9853ef46c2a4410d9008b08b40","7de22db2ebcb4bc8aa578177fbe61a8b","c1d572ac1e1c4e83a8de1126eae609bc","4a4466fcaeb74a0ba7d5f4c627a6d44b","d3e4a71428f64b9d98478725f8dd53d7","f4e8a13edd1b4cc6b8b44c3a4e031f8d"]},"executionInfo":{"elapsed":63115,"status":"ok","timestamp":1748294818865,"user":{"displayName":"Rodrigo Lopes","userId":"06191758959451429758"},"user_tz":180},"id":"Ls_sZYxxNWW8","outputId":"e62bdabb-79de-463e-a0a9-5f89c97b4faf"},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:bitsandbytes.cextension:The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"]},{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/10 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"547c50db9da34732bc3de6be1a19e1af"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","<ipython-input-10-3c017ffaa2d9>:41: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n","  trainer = Trainer(\n","No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [10/10 00:56, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>10</td>\n","      <td>3.485900</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=10, training_loss=3.4858776092529298, metrics={'train_runtime': 61.5444, 'train_samples_per_second': 0.162, 'train_steps_per_second': 0.162, 'total_flos': 3100702519296.0, 'train_loss': 3.4858776092529298, 'epoch': 1.0})"]},"metadata":{},"execution_count":10}],"source":["from peft import get_peft_model, LoraConfig, TaskType\n","from transformers import TrainingArguments, Trainer, DataCollatorForLanguageModeling\n","import os\n","os.environ[\"WANDB_DISABLED\"] = \"true\"\n","\n","# Configura√ß√£o LoRA\n","peft_config = LoraConfig(\n","    task_type=TaskType.CAUSAL_LM,\n","    inference_mode=False,\n","    r=8,\n","    lora_alpha=16,\n","    lora_dropout=0.1\n",")\n","\n","# Aplicar PEFT no modelo\n","model = get_peft_model(model, peft_config)\n","\n","# Tokeniza√ß√£o\n","def tokenize_function(examples):\n","    combined = [\n","        instr + \"\\n\" + resp\n","        for instr, resp in zip(examples['instruction'], examples['response'])\n","    ]\n","    return tokenizer(combined, truncation=True)\n","\n","tokenized_dataset = dataset.map(tokenize_function, batched=True)\n","\n","# Data Collator\n","data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n","\n","# Argumentos de treinamento\n","training_args = TrainingArguments(\n","    output_dir=\"./finetuned_model\",\n","    per_device_train_batch_size=1,\n","    num_train_epochs=1,  # Aumente para resultados reais\n","    save_steps=10,\n","    logging_steps=10\n",")\n","\n","# Trainer\n","trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_dataset,\n","    tokenizer=tokenizer,\n","    data_collator=data_collator\n",")\n","\n","# Iniciar Fine-tuning\n","trainer.train()\n"]},{"cell_type":"markdown","metadata":{"id":"I6aUg6YqQf5p"},"source":["‚úÖ Esse resultado est√° bom?\n","Sim, considerando que o objetivo era testar e validar o pipeline de fine-tuning.\n","\n","Para um fine-tuning real, normalmente usamos:\n","\n","Mais √©pocas (num_train_epochs=3~10).\n","\n","Ajuste de learning_rate.\n","\n","Batch maior, se a infra permitir.\n","\n","Avalia√ß√£o em um conjunto de valida√ß√£o."]},{"cell_type":"markdown","metadata":{"id":"dblFIu4DRHsI"},"source":["‚úÖ Parte 4: Avalia√ß√£o do Modelo Ap√≥s o Fine-Tuning\n","O que est√° acontecendo:\n","Reutilizamos a pipeline.\n","\n","Geramos resposta para o mesmo exemplo anterior.\n","\n","Compararmos antes e depois do fine-tuning.\n","\n"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46535,"status":"ok","timestamp":1748295700524,"user":{"displayName":"Rodrigo Lopes","userId":"06191758959451429758"},"user_tz":180},"id":"E_dSZUNhPdGH","outputId":"bdba553e-3bc9-4b3d-f3b7-19b378282277"},"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cpu\n"]},{"output_type":"stream","name":"stdout","text":["Resposta DEPOIS do fine-tuning:\n"," What is Girls Ballet Tutu Neon?\n","Girls Ballet Tutu Neon is a product that is designed to provide a fun and colorful experience for girls. It is a tutu that is designed to be worn by girls and is made from a neon fabric. The tutu is designed to be comfortable and easy to wear, and it is perfect for ballet classes or other dance performances. The neon fabric is a fun and eye-catching color that will make any girl feel like a ballerina.\n"]}],"source":["from transformers import pipeline\n","\n","# N√ÉO precisa do merge_and_unload\n","pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n","\n","input_prompt = \"What is Girls Ballet Tutu Neon?\"\n","\n","# Infer√™ncia\n","output_after = pipe(input_prompt, max_new_tokens=100)\n","\n","# Exibir\n","print(\"Resposta DEPOIS do fine-tuning:\\n\", output_after[0]['generated_text'])\n"]},{"cell_type":"markdown","source":["üö® Fluxo resumido:\n","Antes do fine-tuning: cria pipeline com modelo base e gera texto.\n","\n","Depois do fine-tuning: aplica LoRA (merge_and_unload()), cria nova pipeline e gera texto.\n","\n","Compara os resultados.\n","\n"],"metadata":{"id":"Guma9tz8g8fY"}},{"cell_type":"code","source":["import torch\n","import math\n","from transformers import pipeline\n","\n","def calculate_perplexity(model, tokenizer, input_text):\n","    model.eval()\n","    with torch.no_grad():\n","        inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n","        outputs = model(**inputs, labels=inputs['input_ids'])\n","        loss = outputs.loss\n","        perplexity = math.exp(loss.item())\n","    return perplexity\n","\n","# --- Prompt para teste ---\n","input_prompt = \"What is Girls Ballet Tutu Neon?\"\n","\n","# --- Infer√™ncia qualitativa (gera√ß√£o de texto) ---\n","\n","# Pipeline do modelo base (antes do fine-tuning)\n","pipe_before = pipeline(\"text-generation\", model=base_model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n","output_before = pipe_before(input_prompt, max_new_tokens=100)\n","print(\"Resposta ANTES do fine-tuning:\\n\", output_before[0]['generated_text'])\n","\n","# Pipeline do modelo fine-tuned (sem merge_and_unload)\n","pipe_after = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0 if torch.cuda.is_available() else -1)\n","output_after = pipe_after(input_prompt, max_new_tokens=100)\n","print(\"\\nResposta DEPOIS do fine-tuning:\\n\", output_after[0]['generated_text'])\n","\n","# --- Compara√ß√£o Quantitativa: Perplexity ---\n","\n","# Perplexity antes do fine-tuning\n","ppl_before = calculate_perplexity(base_model, tokenizer, input_prompt)\n","print(f\"\\nPerplexity ANTES do fine-tuning: {ppl_before:.4f}\")\n","\n","# Perplexity depois do fine-tuning\n","ppl_after = calculate_perplexity(model, tokenizer, input_prompt)\n","print(f\"Perplexity DEPOIS do fine-tuning: {ppl_after:.4f}\")\n","\n","# --- Avalia√ß√£o ---\n","improvement = ppl_before - ppl_after\n","print(f\"\\nDiferen√ßa de Perplexity (antes - depois): {improvement:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B29458dXhAEA","executionInfo":{"status":"ok","timestamp":1748295860528,"user_tz":180,"elapsed":94299,"user":{"displayName":"Rodrigo Lopes","userId":"06191758959451429758"}},"outputId":"9fdd19fd-2c9d-4f7f-fa15-a9ea0c962cce"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["Device set to use cpu\n","Device set to use cpu\n"]},{"output_type":"stream","name":"stdout","text":["Resposta ANTES do fine-tuning:\n"," What is Girls Ballet Tutu Neon?\n","Girls Ballet Tutu Neon is a product that is designed to provide a fun and exciting way for girls to dance. The tutu is made from a soft and stretchy material that is perfect for dancing. The tutu is designed to be comfortable and easy to move in. The tutu is also designed to be lightweight, so that girls can move around easily and not feel weighed down.\n","The tutu is available in a variety of colors, including\n","\n","Resposta DEPOIS do fine-tuning:\n"," What is Girls Ballet Tutu Neon?\n","Girls Ballet Tutu Neon is a product that is designed to provide a fun and colorful experience for girls. It is a tutu that is designed to be worn by girls and is made from a neon fabric. The tutu is designed to be comfortable and easy to wear, and it is perfect for ballet classes or other dance performances. The neon fabric is a fun and eye-catching color that will make any girl feel like a ballerina.\n","\n","Perplexity ANTES do fine-tuning: 287.6886\n","Perplexity DEPOIS do fine-tuning: 284.1963\n","\n","Diferen√ßa de Perplexity (antes - depois): 3.4922\n"]}]},{"cell_type":"markdown","source":["An√°lise r√°pida do resultado:\n","Gera√ß√£o antes do fine-tuning: Texto coerente, mas mais gen√©rico e repetitivo.\n","\n","Gera√ß√£o depois do fine-tuning: Texto mais espec√≠fico, com termos mais alinhados ao prompt (\"colorful experience\", \"neon fabric\"), indicando que o modelo aprendeu nuances do seu dataset.\n","\n","Perplexity: Caiu de 287.7 para 284.2, uma melhora modesta, que indica o modelo est√° um pouco mais confiante na previs√£o dos tokens ap√≥s o fine-tuning."],"metadata":{"id":"Jh78yLpIjpSu"}}],"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPEQcK8m8IH2G9pHg86iLJt"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"547c50db9da34732bc3de6be1a19e1af":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6cd2f1ec6bd4fc4a39da8a7206770e4","IPY_MODEL_0912fdd889f34d2691c29e9a2b16fb36","IPY_MODEL_c27ffa6bc4b04a3085bfadafc19237af"],"layout":"IPY_MODEL_34f5eebd41ca438ea93a7d609e55b1e8"}},"d6cd2f1ec6bd4fc4a39da8a7206770e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3280a9853ef46c2a4410d9008b08b40","placeholder":"‚Äã","style":"IPY_MODEL_7de22db2ebcb4bc8aa578177fbe61a8b","value":"Map:‚Äá100%"}},"0912fdd889f34d2691c29e9a2b16fb36":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c1d572ac1e1c4e83a8de1126eae609bc","max":10,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4a4466fcaeb74a0ba7d5f4c627a6d44b","value":10}},"c27ffa6bc4b04a3085bfadafc19237af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d3e4a71428f64b9d98478725f8dd53d7","placeholder":"‚Äã","style":"IPY_MODEL_f4e8a13edd1b4cc6b8b44c3a4e031f8d","value":"‚Äá10/10‚Äá[00:00&lt;00:00,‚Äá118.48‚Äáexamples/s]"}},"34f5eebd41ca438ea93a7d609e55b1e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3280a9853ef46c2a4410d9008b08b40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7de22db2ebcb4bc8aa578177fbe61a8b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1d572ac1e1c4e83a8de1126eae609bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a4466fcaeb74a0ba7d5f4c627a6d44b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d3e4a71428f64b9d98478725f8dd53d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4e8a13edd1b4cc6b8b44c3a4e031f8d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}